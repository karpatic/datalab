{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do you see this? - Carlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hello world! - Michael"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking - Brian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scooter Exploration\n",
    "\n",
    "Members: Brian Kelly, Michael Vandi, Logan Shertz, Charles Karpati\n",
    "\n",
    "Dataset: Scooter data: \n",
    "- Routes: 3 months (September to August 2019)\n",
    "- Deployment/  \n",
    "- Routes/ \n",
    "- 'Trip origins-destinations by month'/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About Blurb Right Here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Local File Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Run this cell to gain access to Google Drive (Colabs only) \n",
    "from google.colab import drive\n",
    "\n",
    "# Colabs operates in a virtualized enviornment\n",
    "# Colabs default directory is at ~/content.\n",
    "# We mount Drive into a temporary folder at '~/content/drive' \n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your file path will be different\n",
    "! cd ./drive/'My Drive'/BNIA/responsive_records/Routes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Michael's Directory\n",
    "# cd ./drive/'My Drive'/BNIA/'Scooter Use Data'/BNIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ./Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../ && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Installs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install dexplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipyleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gpdvega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dataplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import dexplot as dxp\n",
    "import folium as fol\n",
    "import json\n",
    "import altair as alt\n",
    "import gpdvega\n",
    "import dataplay\n",
    "# These imports will handle everything\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import psycopg2\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "# conda install -c conda-forge proj4\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkb\n",
    "from shapely.wkt import loads\n",
    "# https://pypi.org/project/geopy/\n",
    "from geopy.geocoders import Nominatim\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "from dataplay.merge import mergeDatasets \n",
    "\n",
    "import dexplot as dxp\n",
    "\n",
    "# In case file is KML, enable support\n",
    "import fiona\n",
    "fiona.drvsupport.supported_drivers['kml'] = 'rw'\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning Start and End coordianates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_left = gdf.copy()\n",
    "gdf_left = gdf_left.drop(columns = ['geometry','rightx', 'righty'])\n",
    "\n",
    "gdf_right= gdf.copy()\n",
    "gdf_right = gdf_right.drop(columns = ['geometry','leftx', 'lefty'])\n",
    "\n",
    "gdf_right.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell is good to copy\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# only works with linstrings right now\n",
    "def split(geom):\n",
    "  print( str( type(geom)) )\n",
    "  #Linestring might not be the actual type, so this may need to be fied. \n",
    "  #IF its not a linestring then dont run it and stuff 'false' and the datatype\n",
    "  if str( type(geom)) == \"<class 'shapely.geometry.linestring.LineString'>\" and not str(geom.boundary) == 'MULTIPOINT EMPTY':\n",
    "    print(geom.boundary)\n",
    "    left, right = geom.boundary\n",
    "    print('left x: ', type(left.x), left.x)\n",
    "    print('left y: ', type(left.y), left.y)\n",
    "    print('right x: ', type(right.x), right.x)\n",
    "    print('right y: ', type(right.y), right.y)\n",
    "    return left.x, left.y, right.x, right.y\n",
    "  else: return False, type(geom), False, type(geom)\n",
    "\n",
    "gdf = gdf[~gdf.isna()]\n",
    "gdf = gdf[~gdf.is_empty]\n",
    " \n",
    "# This has been updated too\n",
    "gdf['leftx'], gdf['lefty'],gdf['rightx'], gdf['righty'] = zip(*gdf[\"geometry\"].map(split))\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "temp_gdf = gpd.GeoDataFrame(\n",
    "    gdf_right, geometry=gpd.points_from_xy(gdf_right.rightx, gdf_right.righty))\n",
    "temp_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_right.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_right['rightx']=pd.to_numeric(gdf_right['rightx'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_right.to_csv('rightRouts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_right['righty'] = gdf_right['righty'].astype(str)\n",
    "gdf_right.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataplay.geoms import readInGeometryData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "#gdf_right['geometry'] = gdf_right['right'].apply(wkt.loads)\n",
    "gdf_right['strCol']=gdf_right['right'].astype(str)\n",
    "gdf_right['geometry'] = gdf_right['strCol'].apply(wkt.loads)\n",
    "gdf_right.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is good to copy\n",
    "from shapely.geometry import LineString\n",
    " \n",
    "def split(geom): \n",
    "    print( str( type(geom) ) )\n",
    "    print(not geom.is_empty)\n",
    "    if str( type(geom) ) == \"<class 'shapely.geometry.linestring.LineString'>\" or str(geom.boundary) == 'MULTIPOINT EMPTY':\n",
    "    \n",
    "      print('First print')\n",
    "      left, right = geom.boundary\n",
    "      \n",
    "      # This is new\n",
    "      print('left x: ', type(left.x), left.x)\n",
    "      print('left y: ', type(left.y), left.y)\n",
    "      print('right x: ', type(right.x), right.x)\n",
    "      print('right y: ', type(right.y), right.y)\n",
    "      \n",
    "      return left.x, left.y, right.x, right.y\n",
    "    else: return False, type(geom)\n",
    " \n",
    "gdf = gdf[~gdf.isna() ]\n",
    "gdf = gdf[~gdf.is_empty]\n",
    " \n",
    "# This has been updated too\n",
    "gdf['leftx'], gdf['lefty'],gdf['rightx'], gdf['righty'] = zip(*gdf[\"geometry\"].map(split))\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataplay.geoms import readInGeometryData\n",
    "\n",
    "#gdf_right['geometry'] = gdf_right['strCol'].apply(lambda x: loads( str(x) ))\n",
    "csaMap = readInGeometryData(url=gdf_right, porg='p', geom= False, lat= 'rightx', lng= 'righty', revgeocode=False, save=False, in_crs=4268, out_crs=4268)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### File Access Conveince Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Relative Path to Files\n",
    "def findFile(root, file):\n",
    "    for d, subD, f in os.walk(root):\n",
    "        if file in f:\n",
    "            return \"{1}/{0}\".format(file, d)\n",
    "            break \n",
    "\n",
    "# To 'import' a script you wrote, map its filepath into the sys\n",
    "def addPath(root, file): sys.path.append(os.path.abspath( findFile( './', file) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findFile('./', 'Routing September 2019.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Deployment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls 'Trip origins-destinations by month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Example form fields\n",
    "#@markdown Forms support many types of fields.\n",
    "fileName = \"Trip Destinations by block August 2019.geojson\"  #@param ['Daily Deployment average by block August 2019.csv', 'Daily Deployment average by block December 2019.csv', 'Daily Deployment average by block November 2019.csv', 'Daily Deployment average by block October 2019.csv', 'Daily Deployment average by block September 2019.csv', 'Trip Destinations by block August 2019.geojson','Trip Destinations by block December 2019.geojson','Trip Destinations by block November 2019.geojson', 'Trip Destinations by block October 2019.geojson', 'Trip Destinations by block September 2019.geojson', 'Trip Origins by block August 2019.geojson','Trip Origins by block December 2019.geojson','Trip Origins by block November 2019.geojson','Trip Origins by block October 2019.geojson','Trip Origins by block September 2019.geojson']\n",
    "#@markdown ---\n",
    "\n",
    "\n",
    "\n",
    "df = gpd.read_file( findFile('./', fileName) )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(column = 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_df = df.copy()\n",
    "point_df['centroids'] = df.centroid\n",
    "point_df = point_df.drop(columns = 'geometry')\n",
    "point_df = point_df.set_geometry('centroids')\n",
    "point_df.head(1)\n",
    "point_df.plot(marker='o', color='red', markersize='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_df.value.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_df[point_df.value > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore = gpd.read_file(\"https://opendata.arcgis.com/datasets/b738a8587b6d479a8824d937892701d8_0.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataplay.geoms import workWithGeometryData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsInPolys = workWithGeometryData(method = 'ponp', df = point_df, polys = baltimore, ptsCoordCol ='centroids', \n",
    "                                     polygonsCoordCol = 'geometry', polygonsLabel = 'CSA2010')\n",
    "pointsInPolys.plot(column='value', legend=True, markersize = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy = pointsInPolys.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy.value.isnull().groupby([ponp_copy['CSA2010']]).sum().astype(int).reset_index(name='NumberMissingCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy.value.notnull().groupby([ponp_copy['CSA2010']]).sum().astype(int).reset_index(name='NumberNotMissingCount') /\n",
    "ponp_copy.value.isnull().groupby([ponp_copy['CSA2010']]).sum().astype(int).reset_index(name='NumberMissingCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy.value.notnull().groupby([ponp_copy['CSA2010']]).sum().astype(int) / ponp_copy.value.isnull().groupby([ponp_copy['CSA2010']]).sum().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy.value.isnull().groupby([ponp_copy['CSA2010']]).sum().astype(int) / ponp_copy.value.groupby([ponp_copy['CSA2010']]).sum().astype(int) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy.fillna(-1).groupby('CSA2010')['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy['value'] = pd.to_numeric(ponp_copy['value'], errors='coerce')\n",
    "ponp_copy = ponp_copy.replace(np.nan, 0, regex = True)\n",
    "ponp_copy_grouped = ponp_copy.groupby('CSA2010').mean()\n",
    "# ponp_copy_grouped.head()\n",
    "ponp_copy_grouped = ponp_copy_grouped.reset_index()\n",
    "# ponp_copy_grouped.filter(lambda x: x['value'].astype(int) > 3)\n",
    "ponp_copy_grouped = ponp_copy_grouped[ponp_copy_grouped.value > 3]\n",
    "ponp_copy_grouped.head()\n",
    "\n",
    "\n",
    "# ponp_copy.groupby(ponp_copy.groupby('CSA2010')['value'].mean > 50)\n",
    "# ponp_copy.groupby('CSA2010')['value'][ ponp_copy.groupby('CSA2010')['value'].mean()>50 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baltimore.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy_grouped = ponp_copy_grouped.merge(baltimore, left_on='CSA2010', right_on='CSA2010')\n",
    "ponp_copy_groupedV2 = gpd.GeoDataFrame(ponp_copy_grouped, geometry='geometry')\n",
    "ponp_copy_groupedV2.plot(column = 'value', legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panp = workWithGeometryData( 'pandp', foodPantryLocations[ foodPantryLocations.City_1 == 'Baltimore' ], pointsInPolys, polyColorCol='number of points')\n",
    "panp = workWithGeometryData( method = 'pandp', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy.groupby('CSA')['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponp_copy.CSA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value.var() # Return unbiased variance over requested axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value.sem() # Return unbiased standard error of the mean over requested axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value.nunique()\t# Count distinct observations over requested axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.shape\tReturn a tuple representing the dimensionality of the DataFrame.\n",
    "df.shape\n",
    "\n",
    "#DataFrame.size\tReturn an int representing the number of elements in this object.\n",
    "df.size\n",
    "\n",
    "# DataFrame.ndim\tReturn an int representing the number of axes / array dimensions.\n",
    "df.ndim\n",
    "\n",
    "# Note Used : \n",
    "# DataFrame.axes\tReturn a list representing the axes of the DataFrame.\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "# Return unbiased kurtosis over requested axis using Fisher’s definition of kurtosis (kurtosis of normal == 0.0).\n",
    "df.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nameChange1'] = df.name.str.replace('Block ', '')\n",
    "df['nameChange2'] = df['nameChange1'].map(lambda x: str(x)[:-4])\n",
    "df['nameChange1Remainder'] = df['nameChange2'].map(lambda x: str(x)[-4:])\n",
    "scooterdf = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will just beautify the output\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The attributes are what we will use.\n",
    "in_crs = 2248 # The CRS we recieve our data \n",
    "out_crs = 4326 # The CRS we would like to have our data represented as\n",
    "geom = 'geometry' # The column where our spatial information lives.\n",
    "\n",
    "# A Url to load\n",
    "boundariesBaltimoreTractsNoWater2010 = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ8xXdUaT17jkdK0MWTJpg3GOy6jMWeaXTlguXNjCSb8Vr_FanSZQRaTU-m811fQz4kyMFK5wcahMNY/pub?gid=886223646&single=true&output=csv\"\n",
    "\n",
    "# Read in the dataframe\n",
    "gdf = pd.read_csv(boundariesBaltimoreTractsNoWater2010)\n",
    "\n",
    "# Convert the geometry column datatype from a string of text into a coordinate datatype\n",
    "gdf['geometry'] = gdf['geometry'].apply(lambda x: loads( str(x) ))\n",
    "\n",
    "# Process the dataframe as a geodataframe with a known CRS and geom column\n",
    "gdf = GeoDataFrame(gdf, crs=in_crs, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundariesBaltimoreTractsNoWater2010.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure merge is on consistent datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['GEOID10'] = gdf['GEOID10'].astype(str)\n",
    "scooterdf['nameChange2'] = scooterdf['nameChange2'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean = gdf.merge(scooterdf, left_on='GEOID10', right_on='nameChange2').drop(['name', 'nameChange1', 'nameChange2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scooterdf.to_csv('./scooterdf.csv', index=False)\n",
    "# gdf.drop(columns='geometry').to_csv('./boundsdf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.groupby('CSA')['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.value.isna().groupby([scooterdfClean['CSA']]).sum().astype(int).reset_index(name='notApplicable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.value.notnull().groupby([scooterdfClean['CSA']]).sum().astype(int).reset_index(name='NotMissingCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.value.isnull().groupby([scooterdfClean['CSA']]).sum().astype(int).reset_index(name='NumberMissingCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.fillna(-1).groupby('CSA')['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.groupby('CSA')['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.groupby('CSA')['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.CSA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Routes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = fol.Map(location = [39.2, -76.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Example form fields\n",
    "#@markdown Forms support many types of fields.\n",
    "fileName = 'Routing December 2019.geojson'  #@param ['Routing August 2019.geojson', 'Routing October 2019.geojson', 'Routing December 2019.geojson', 'Routing September 2019.geojson', 'Routing November 2019.geojson']\n",
    "columnName = \"streetname\"  #@param ['id', 'color', 'streetname', 'trip_count_sum', 'trip_count_average', 'trip_count_percent']\n",
    "\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "gdf = gpd.read_file( findFile('./', fileName) )\n",
    "\n",
    "\n",
    "\n",
    "gdf.plot( column = columnName)\n",
    "gdf.columns\n",
    "gdf [['id', 'color', 'streetname', 'trip_count_sum', 'trip_count_average', 'trip_count_percent']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "tract = gpd.read_file( findFile('./', fileName) )\n",
    "tract.head(1)\n",
    "tract.crs\n",
    "\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "\n",
    "fileName = 'Routing December 2019.geojson'  #@param ['Routing August 2019.geojson', 'Routing October 2019.geojson', 'Routing December 2019.geojson', 'Routing September 2019.geojson', 'Routing November 2019.geojson']\n",
    "gdf = gpd.read_file( findFile('./', fileName) )\n",
    "\n",
    "columnName = \"trip_count_sum\"  #@param ['id', 'color', 'streetname', 'trip_count_sum', 'trip_count_average', 'trip_count_percent']\n",
    "\n",
    "background = alt.Chart(gdf).mark_geoshape(\n",
    "    stroke='white',\n",
    "    strokeWidth=2\n",
    ").encode(\n",
    "    color=alt.value('#eee'),\n",
    ").properties(\n",
    "    width=700,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "baltimore = gpd.read_file(\"https://opendata.arcgis.com/datasets/b738a8587b6d479a8824d937892701d8_0.geojson\")\n",
    "\n",
    "# GeoDataFrame could be passed as usual pd.DataFrame\n",
    "city = alt.Chart(baltimore).mark_geoshape(\n",
    ").project(\n",
    ").encode(\n",
    "    color='tpop10', # shorthand infer types as for regular pd.DataFrame\n",
    "    tooltip='CSA2010' # GeoDataFrame.index is accessible as id\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "routes = alt.Chart(gdf).mark_geoshape(\n",
    "    filled=False,\n",
    "    strokeWidth=2\n",
    ")\n",
    "\n",
    "city + routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To 'import' a script you wrote, map its filepath into the sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def getPolygonOnPoints(pts, polygons, ptsCoordCol, polygonsCoordCol, polygonsLabel): \n",
    "  count = 0 \n",
    "  # We're going to keep a list of how many points we find.\n",
    "  boundaries = []\n",
    "\n",
    "  # Loop over polygons with index i.\n",
    "  for i, pt in pts.iterrows():\n",
    "  # print('Searching for point within Geom:', pt )\n",
    "  # Only one Label is accepted.\n",
    "    poly_on_this_point = 'false'\n",
    "  # Now loop over all polygons with index j. \n",
    "  for j, poly in polygons.iterrows():\n",
    "    if poly[polygonsCoordCol].intersects(pt[ptsCoordCol]):\n",
    "    # Then it's a hit! Add it to the list\n",
    "     poly_on_this_point = poly[polygonsLabel] \n",
    "     count = count + 1 \n",
    "      # pts = pts.drop([j])\n",
    "\n",
    "  # We could do all sorts, like grab a property of the\n",
    "  # points, but let's just append the number of them.\n",
    "    boundaries.append(poly_on_this_point)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "  # Add the number of points for each poly to the dataframe.\n",
    "  pts = pts.assign(CSA2010 = boundaries) \n",
    "  print( 'Total Points: ', (pts.size / len(pts.columns) ) )\n",
    "  print( 'Total Points in Polygons: ', count )\n",
    "  print( 'Prcnt Points in Polygons: ', count / (pts.size / len(pts.columns) ) )\n",
    "  return pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final Version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "tract = gpd.read_file( findFile('./', fileName) )\n",
    "tract.head(1)\n",
    "tract.crs\n",
    "\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "\n",
    "fileName = 'Routing October 2019.geojson'  #@param ['Routing August 2019.geojson', 'Routing October 2019.geojson', 'Routing December 2019.geojson', 'Routing September 2019.geojson', 'Routing November 2019.geojson']\n",
    "gdf = gpd.read_file( findFile('./', fileName) )\n",
    "\n",
    "background = alt.Chart(gdf).mark_geoshape(\n",
    "    stroke='white',\n",
    "    strokeWidth=2\n",
    ").encode(\n",
    "    color=alt.value('#eee'),\n",
    ").properties(\n",
    "    width=700,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "baltimore = gpd.read_file(\"https://opendata.arcgis.com/datasets/b738a8587b6d479a8824d937892701d8_0.geojson\")\n",
    "\n",
    "# GeoDataFrame could be passed as usual pd.DataFrame\n",
    "city = alt.Chart(baltimore).mark_geoshape(\n",
    ").project(\n",
    ").encode(\n",
    "    color='tpop10', # shorthand infer types as for regular pd.DataFrame\n",
    "    tooltip='CSA2010' # GeoDataFrame.index is accessible as id\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "routes = alt.Chart(gdf).mark_geoshape(\n",
    "    filled=False,\n",
    "    strokeWidth=2\n",
    ")\n",
    "\n",
    "city + routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "world.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once installed we need to import and configure the Widgets\n",
    "import ipywidgets as widgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "tract = gpd.read_file( findFile('./', fileName) )\n",
    "tract.head(1)\n",
    "tract.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring the Merge is consistent on Data Types (Route)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['GEOID10'] = gdf['GEOID10'].astype(str)\n",
    "scooterdf['nameChange2'] = scooterdf['nameChange2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean = gdf.merge(scooterdf, left_on='GEOID10', right_on='nameChange2').drop(['name', 'nameChange1', 'nameChange2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scooterdf.to_csv('./scooterdf.csv', index=False)\n",
    "# gdf.drop(columns='geometry').to_csv('./boundsdf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.groupby('CSA')['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.value.isna().groupby([scooterdfClean['CSA']]).sum().astype(int).reset_index(name='notApplicable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.value.notnull().groupby([scooterdfClean['CSA']]).sum().astype(int).reset_index(name='NotMissingCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.value.isnull().groupby([scooterdfClean['CSA']]).sum().astype(int).reset_index(name='NumberMissingCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.fillna(-1).groupby('CSA')['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.groupby('CSA')['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.groupby('CSA')['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooterdfClean.CSA.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Origins-Destinations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls 'Trip origins-destinations by month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Example form fields\n",
    "#@markdown Forms support many types of fields.\n",
    "fileName = 'Trip Destinations by block August 2019.geojson'  #@param ['Trip Destinations by block August 2019.geojson', 'Trip Destinations by block December 2019.geojson', 'Trip Destinations by block November 2019.geojson', 'Trip Destinations by block October 2019.geojson', 'Trip Destinations by block September 2019.geojson', 'Trip Origins by block August 2019.geojson', 'Trip Origins by block December 2019.geojson', 'Trip Origins by block November 2019.geojson', 'Trip Origins by block October 2019.geojson', 'Trip Origins by block September 2019.geojson']\n",
    "columnName = \"name\"  #@param ['name', 'value', 'color', 'radius']\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "gdf = gpd.read_file( findFile('./', fileName) )\n",
    "\n",
    "gdf.plot( column = columnName)\n",
    "gdf.columns\n",
    "gdf[['id','name', 'value', 'color', 'radius']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxp.bar(x='color', y='value', data=gdf, aggfunc='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxp.scatter(x = \"color\", y = \"value\", data = gdf, aggfunc = \"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Old Routes Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To 'import' a script you wrote, map its filepath into the sys\n",
    "def getPointsInPolygons(pts, polygons, ptsCoordCol, polygonsCoordCol): \n",
    "    count = 0 \n",
    "    total = pts.size / len(pts.columns)\n",
    "    # We're going to keep a list of how many points we find.\n",
    "    pts_in_polys = []\n",
    "\n",
    "    # Loop over polygons with index i.\n",
    "    for i, poly in polygons.iterrows():\n",
    "        # print('Searching for point within Geom:', poly )\n",
    "        # Keep a list of points in this poly\n",
    "        pts_in_this_poly = []\n",
    "\n",
    "        # Now loop over all points with index j.\n",
    "    for j, pt in pts.iterrows():\n",
    "        if poly[polygonsCoordCol].contains(pt[ptsCoordCol]):\n",
    "        # Then it's a hit! Add it to the list,\n",
    "        # and drop it so we have less hunting.\n",
    "        pts_in_this_poly.append(pt[ptsCoordCol])\n",
    "        pts = pts.drop([j])\n",
    "\n",
    "      # We could do all sorts, like grab a property of the\n",
    "      # points, but let's just append the number of them.\n",
    "      pts_in_polys.append(len(pts_in_this_poly))\n",
    "      print('Found this many points within the Geom:', len(pts_in_this_poly) ) \n",
    "      count = count + len(pts_in_this_poly) \n",
    "      clear_output(wait=True)\n",
    "\n",
    "    # Add the number of points for each poly to the dataframe.\n",
    "    polygons['pointsinpolygon'] = gpd.GeoSeries(pts_in_polys)\n",
    "    print( 'Total Points: ', total )\n",
    "    print( 'Total Points in Polygons: ', count )\n",
    "    print( 'Prcnt Points in Polygons: ', count / total )\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Charles code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
